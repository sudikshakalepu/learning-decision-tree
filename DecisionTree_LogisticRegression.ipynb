{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "UzY5NDgsYmn5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is an INDIVIDUAL Assignment. Collaboration with other students is strictly prohibited"
      ],
      "metadata": {
        "id": "1-2oTts4lh-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Decision Tree from Scratch"
      ],
      "metadata": {
        "id": "XgI97LJuZEZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Node Representation [3 points]**\n",
        "\n",
        "- **Purpose**: Represents a node in the decision tree, which can either be a leaf or an internal node.\n",
        "- **Attributes**:\n",
        "  - `is_leaf` (bool): To determine if the node is a leaf node.\n",
        "  - `feature_index` (int): The feature index used to split.\n",
        "  - `threshold` (float): The threshold value used to split the data.\n",
        "  - `prediction` (int): The value of the prediction (if the node is a leaf).\n",
        "  - `left` (dict): Left child node.\n",
        "  - `right` (dict): Right child node."
      ],
      "metadata": {
        "id": "nX6s0Eo0ZH_3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hmxsBreMVrvw"
      },
      "outputs": [],
      "source": [
        "def create_node(\n",
        "    is_leaf: bool,\n",
        "    feature_index: int = -1,\n",
        "    threshold: float = -1,\n",
        "    prediction: float = None,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Creates a decision tree node.\n",
        "\n",
        "    Args:\n",
        "        is_leaf (bool): Whether the node is a leaf node.\n",
        "        feature_index (int): The feature index used for splitting.\n",
        "        threshold (float): The threshold value for splitting.\n",
        "        prediction (float): The prediction value for leaf nodes.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary representing a decision tree node.\n",
        "    \"\"\"\n",
        "    # fill code here\n",
        "\n",
        "    return {\n",
        "        \"is_leaf\": is_leaf,\n",
        "        \"feature_index\": feature_index,\n",
        "        \"threshold\": threshold,\n",
        "        \"prediction\": prediction,\n",
        "        \"left\": None,\n",
        "        \"right\": None\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Splitting Dataset [4 points]**\n",
        "\n",
        "- **Purpose**: Split the dataset into left and right parts based on a given feature and threshold.\n",
        "-\n",
        "  - Iterate through each instance in the dataset.\n",
        "  - Compare the value of the selected feature with the given threshold.\n",
        "  - Append the instance to either the left or right split based on whether the feature value is less than or equal to the threshold.\n",
        "  - Make sure both the features and labels are split according"
      ],
      "metadata": {
        "id": "qWwt1ez3ZJyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(\n",
        "    df: pd.DataFrame, feature_index: str, threshold: float\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Splits the dataset based on a feature and a threshold.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        feature_index (str): The feature to split on.\n",
        "        threshold (float): The threshold value to use for the split.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the left and right datasets.\n",
        "    \"\"\"\n",
        "    #fill code here\n",
        "    left = df[df[feature_index] <= threshold]\n",
        "    right = df[df[feature_index] > threshold]\n",
        "    return left, right\n",
        ""
      ],
      "metadata": {
        "id": "u4J2x56ZVxyd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking Purity [2 points]**\n",
        "\n",
        "- **Purpose**: Determine if all the labels are the same.\n",
        "-\n",
        "  - If all labels are identical, the node should be considered pure, and it will become a leaf node.\n",
        "  - Check if all elements are the same.\n",
        "  - This function helps determine whether further splitting is necessary."
      ],
      "metadata": {
        "id": "5iLawW9qZt0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_pure(labels: pd.Series) -> bool:\n",
        "    \"\"\"\n",
        "    Checks if all the labels are the same.\n",
        "\n",
        "    Args:\n",
        "        labels (pd.Series): The label values.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all labels are the same, False otherwise.\n",
        "    \"\"\"\n",
        "    # fill code here\n",
        "    return labels.nunique() == 1\n"
      ],
      "metadata": {
        "id": "UzNmFLqpWCET"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding the Best Split [7 points]**\n",
        "\n",
        "- **Purpose**: Find the best feature and threshold to split the dataset.\n",
        "-\n",
        "  - Iterate through each feature and determine possible thresholds.\n",
        "  - Use entropy as the metric to evaluate the quality of the split.\n",
        "  - For each threshold, calculate the entropy of the resulting splits and choose the one with the lowest entropy.\n",
        "  - The best split will minimize the entropy, meaning the resulting splits are as pure as possible.\n"
      ],
      "metadata": {
        "id": "NdVhZnuqeA8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(\n",
        "    df: pd.DataFrame, features: list[str], label_column: str\n",
        ") -> tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Finds the best feature and threshold to split the dataset by minimizing entropy.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        features (list[str]): The list of feature column names.\n",
        "        label_column (str): The label column name.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The feature name and threshold value for the best split.\n",
        "    \"\"\"\n",
        "    best_entropy = float(\"inf\")\n",
        "    best_feature = \"\"\n",
        "    best_threshold = -1\n",
        "\n",
        "    # fill code here\n",
        "\n",
        "    for feature in features:\n",
        "        thresholds = df[feature].unique()\n",
        "        for threshold in thresholds:\n",
        "            left, right = split_dataset(df, feature, threshold)\n",
        "            if len(left) == 0 or len(right) == 0:\n",
        "                continue\n",
        "\n",
        "            entropy = calculate_entropy(left[label_column], right[label_column])\n",
        "            if entropy < best_entropy:\n",
        "                best_entropy = entropy\n",
        "                best_feature = feature\n",
        "                best_threshold = threshold\n",
        "\n",
        "    return best_feature, best_threshold"
      ],
      "metadata": {
        "id": "GiS-ejjLeFfr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Calculating Entropy [7 points]**\n",
        "\n",
        "- **Purpose**: Calculate the entropy for a given split of labels.\n",
        "-\n",
        "  - Entropy is a measure of impurity, where lower values indicate a purer split.\n",
        "  - For each subset of labels (left and right), calculate the proportion of each class.\n",
        "  - Use the formula for entropy\n",
        "  - The entropy for the split is the weighted average of the left and right entropies.\n"
      ],
      "metadata": {
        "id": "2kPYPXJsZzZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(left_labels: pd.Series, right_labels: pd.Series) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the entropy for a split.\n",
        "\n",
        "    Args:\n",
        "        left_labels (pd.Series): The label values for the left split.\n",
        "        right_labels (pd.Series): The label values for the right split.\n",
        "\n",
        "    Returns:\n",
        "        float: The entropy value for the split.\n",
        "    \"\"\"\n",
        "\n",
        "    left_size = len(left_labels)\n",
        "    right_size = len(right_labels)\n",
        "    total_size = left_size + right_size\n",
        "\n",
        "    if total_size == 0:\n",
        "        return 0\n",
        "\n",
        "    def entropy(labels):\n",
        "        # fill code here\n",
        "        counts = np.bincount(labels)\n",
        "        probabilities = counts / len(labels)\n",
        "        return -sum(p * np.log2(p) for p in probabilities if p > 0)\n",
        "\n",
        "    # Calculate entropy for both left and right splits\n",
        "    entropy_left = entropy(left_labels)\n",
        "    entropy_right = entropy(right_labels)\n",
        "\n",
        "    # Weighted average of both entropies\n",
        "    entropy_left = entropy(left_labels)\n",
        "    entropy_right = entropy(right_labels)\n",
        "\n",
        "    # fill code here\n",
        "    return (left_size / total_size) * entropy_left + (right_size / total_size) * entropy_right"
      ],
      "metadata": {
        "id": "BmMedLosXAzy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Calculating Prediction [2 points]**\n",
        "\n",
        "- **Purpose**: Calculate the prediction value for a leaf node (most common label).\n",
        "- **Description**:\n",
        "  - This function returns the most common label in the dataset, which is used as the prediction for a leaf node.\n"
      ],
      "metadata": {
        "id": "wjpKjWbqgiU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prediction(labels: pd.Series) -> int:\n",
        "    \"\"\"\n",
        "    Calculates the prediction value for a leaf node.\n",
        "\n",
        "    Args:\n",
        "        labels (pd.Series): The label values.\n",
        "\n",
        "    Returns:\n",
        "        int: The most common value of the labels.\n",
        "    \"\"\"\n",
        "    # fill code here\n",
        "    return labels.mode()[0]"
      ],
      "metadata": {
        "id": "FmthfOXMggx6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Building the Decision Tree [7 points]**\n",
        "\n",
        "- **Purpose**: Recursively build the decision tree by finding the best split and creating nodes.\n",
        "- **Hints**:\n",
        "  - Start with the current depth as 0 and increase it with each recursive call.\n",
        "  - Stop the recursion if the current depth reaches the maximum depth or if the node is pure.\n",
        "  - Use the `find_best_split` function to determine the best feature and threshold for splitting.\n",
        "  - Create left and right child nodes recursively and attach them to the current node."
      ],
      "metadata": {
        "id": "Ipjqbv6OaGiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(\n",
        "    df: pd.DataFrame,\n",
        "    features: list[str],\n",
        "    label_column: str,\n",
        "    current_depth: int,\n",
        "    max_depth: int,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Builds the decision tree recursively.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataset including features and labels.\n",
        "        features (list[str]): The list of feature column names.\n",
        "        label_column (str): The label column name.\n",
        "        current_depth (int): The current depth of the tree.\n",
        "        max_depth (int): The maximum allowed depth of the tree.\n",
        "\n",
        "    Returns:\n",
        "        dict: The root node of the decision tree.\n",
        "    \"\"\"\n",
        "    # fill code for base case\n",
        "    labels = df[label_column]\n",
        "    if is_pure(labels) or current_depth >= max_depth:\n",
        "        prediction = calculate_prediction(labels)\n",
        "        return create_node(is_leaf=True, prediction=prediction)\n",
        "\n",
        "\n",
        "    # fill code to find best feature\n",
        "    best_feature, best_threshold = find_best_split(df, features, label_column)\n",
        "\n",
        "    # fill code to split the data\n",
        "    if best_feature == \"\":\n",
        "        prediction = calculate_prediction(labels)\n",
        "        return create_node(is_leaf=True, prediction=prediction)\n",
        "\n",
        "    left, right = split_dataset(df, best_feature, best_threshold)\n",
        "\n",
        "    left_child = build_tree(left, features, label_column, current_depth + 1, max_depth)\n",
        "    right_child = build_tree(right, features, label_column, current_depth + 1, max_depth)\n",
        "\n",
        "    node = create_node(is_leaf=False, feature_index=best_feature, threshold=best_threshold)\n",
        "    node[\"left\"] = left_child\n",
        "    node[\"right\"] = right_child\n",
        "\n",
        "    return node"
      ],
      "metadata": {
        "id": "SBbCBDttWEfV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predicting Using the Tree [3 points]**\n",
        "\n",
        "- **Purpose**: Predict the label for a given feature vector using the trained decision tree.\n",
        "- **Hints**:\n",
        "  - Start at the root of the tree and traverse down to a leaf node.\n",
        "  - For each internal node, decide whether to move left or right based on the feature value and threshold.\n",
        "  - When a leaf node is reached, return its prediction value."
      ],
      "metadata": {
        "id": "LTc14KM3Z9d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree: dict, sample: pd.Series) -> int:\n",
        "    \"\"\"\n",
        "    Predicts the label for a given feature vector using the decision tree.\n",
        "\n",
        "    Args:\n",
        "        tree (dict): The root node of the decision tree.\n",
        "        sample (pd.Series): The feature vector.\n",
        "\n",
        "    Returns:\n",
        "        int: The predicted label.\n",
        "    \"\"\"\n",
        "    # fill code here\n",
        "\n",
        "    if tree[\"is_leaf\"]:\n",
        "        return tree[\"prediction\"]\n",
        "\n",
        "    feature_value = sample[tree[\"feature_index\"]]\n",
        "    if feature_value <= tree[\"threshold\"]:\n",
        "        return predict(tree[\"left\"], sample)\n",
        "    else:\n",
        "        return predict(tree[\"right\"], sample)"
      ],
      "metadata": {
        "id": "cKB37Y4yYYg7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using a Real-World Dataset and Comparison with Scikit-Learn"
      ],
      "metadata": {
        "id": "2Iv-KI50a6GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", header=None)\n",
        "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']"
      ],
      "metadata": {
        "id": "ETeO8A8iXPAR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features and labels\n",
        "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
        "label_column = 'class'\n",
        "iris['class'] = iris['class'].apply(lambda x: 0 if x == 'Iris-setosa' else (1 if x == 'Iris-versicolor' else 2))"
      ],
      "metadata": {
        "id": "neBVD1-SgG_n"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing\n",
        "X_train, X_test = train_test_split(iris, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "blmX6OqiXL_U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 3\n",
        "decision_tree = build_tree(X_train, features, label_column, 0, max_depth)"
      ],
      "metadata": {
        "id": "NvLtKsgwXNiu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = X_test.apply(lambda row: predict(decision_tree, row), axis=1)"
      ],
      "metadata": {
        "id": "Ya0vV8bVgwyb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_accuracy = accuracy_score(X_test[label_column], predictions)\n",
        "print(f\"Custom Decision Tree Accuracy: {custom_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TO5Rlqcgytr",
        "outputId": "15d9c882-c19a-48b4-b326-78b46579e643"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
        "clf.fit(X_train[features], X_train[label_column])\n",
        "sklearn_predictions = clf.predict(X_test[features])\n",
        "sklearn_accuracy = accuracy_score(X_test[label_column], sklearn_predictions)\n",
        "print(f\"Scikit-Learn Decision Tree Accuracy: {sklearn_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebSrnFBQXe_f",
        "outputId": "a0511344-6a9f-4b44-983c-c1bf4a359f01"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-Learn Decision Tree Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "sKFhGL2sh9TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Show that: [5 points]\n",
        "\n",
        "$$\n",
        "\\sigma(-x) = 1 - \\sigma(x)\n",
        "$$\n",
        "\n",
        "where\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$"
      ],
      "metadata": {
        "id": "2npBupW1ih72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\sigma(-x) = \\frac{1}{1 + e^{x}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "1 - \\sigma(x) = 1 - \\frac{1}{1 + e^{-x}} = \\frac{e^{-x}}{1 + e^{-x}} = \\frac{\\frac{1}{e^{x}}}{1 + \\frac{1}{e^{x}}} = \\frac{1}{1 + e^{x}} = \\sigma(-x)\n",
        "$$"
      ],
      "metadata": {
        "id": "Uez2imZno59a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Show that: [5 points]\n",
        "\n",
        "$$\n",
        "\\frac{d}{dx}\\sigma(x) = \\sigma(x)(1 - \\sigma(x))\n",
        "$$\n"
      ],
      "metadata": {
        "id": "W4JcVkiRimXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given:\n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "\n",
        "The derivative of $\\sigma(x)$ with respect to $x$ is:\n",
        "\n",
        "$$\n",
        "\\frac{d}{dx}\\sigma(x) = \\frac{d}{dx} \\frac{1}{1 + e^{-x}} = \\frac{e^{-x}}{(1 + e^{-x})^2}\n",
        "$$\n",
        "\n",
        "Now, substitute $\\sigma(x) = \\frac{1}{1 + e^{-x}}$:\n",
        "\n",
        "$$\n",
        "\\frac{d}{dx}\\sigma(x) = {\\frac{1}{1 + e^{-x}}}{\\frac{e^{-x}}{1 + e^{-x}}}  =  \\sigma(x)(1 - \\sigma(x))\n",
        "$$\n"
      ],
      "metadata": {
        "id": "w37UIvvWtTES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Gradient Descent [5 points]\n",
        "You have a univariate function you wish to minimize, $f(w) = 5(w-11)^4$. Suppose you wish to perform gradient descent with constant step size $\\alpha = 1/40$. Starting with $w_0 = 13$, perform 5 steps of gradient descent. What are $w_0, w_1, w_2, w_3, w_4, w_5$? What is the value of $f(w_5)$?"
      ],
      "metadata": {
        "id": "J-BFtOYtjJSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given:\n",
        "\n",
        "$f(w) = 5(w-11)^4$\n",
        "\n",
        "$f'(w) = 20(w-11)^3 $\n",
        "\n",
        "$w_{n+1} = w_n - \\alpha f'(w_n)$\n",
        "\n",
        "$w_0 = 13$\n",
        "\n",
        "$$w_1 = w_0 - \\alpha f'(0) = 13 - \\frac{1}{40} (20 (13-11)^3) = 9 $$\n",
        "\n",
        "$$w_2 = w_1 - \\alpha f'(1) = 9 - \\frac{1}{40} (20 (9-11)^3) = 13 $$\n",
        "\n",
        "$$w_3 = w_2 - \\alpha f'(2) = 13 - \\frac{1}{40} (20 (13-11)^3) = 9 $$\n",
        "\n",
        "$$w_4 = w_3 - \\alpha f'(3) = 9 - \\frac{1}{40} (20 (9-11)^3) = 13 $$\n",
        "\n",
        "$$w_5 = w_4 - \\alpha f'(5) = 13 - \\frac{1}{40} (20 (13-11)^3) = 9 $$\n",
        "\n",
        "$$f(w_5) = 5(9-11)^4 = 80$$"
      ],
      "metadata": {
        "id": "wSO6eY6gznzf"
      }
    }
  ]
}